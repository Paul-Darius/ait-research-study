\setlength{\footskip}{8mm}

\chapter{Methodology}
\label{ch:methodology}

\section{System Design}
The following figure shows the design of the final product. 
\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.5]{figures/design.png}  
  \caption[Design of the final product.]{Design of the final product.}
  \label{fig:Design}
\end{figure}
\FloatBarrier

\section{Solution overview}

The goal of this research is to build an algorithm which can detect our three researchers in the surveillance videos of a mall. There are five steps in this process.
\begin{itemize}
\item Initially, we have a database of videos.\newline
\item Then, these videos are processed to extract the faces of every person appearing in them. We have now a database of faces.\newline
\item From this database are generated some files which are necessery for the learning process.\newline
\item A model is learnt to recognize our researchers.\newline
\item The model is tested.
\end{itemize}

\section{Solution Design}

The following figure presents two main ideas. In blue, the steps described in the above section are shown. In green, the solutions used to go from a step to the next one are described.\newline
\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/methodology.png}  
  \caption[An overview of the global design of the study.]{An overview of the global design of the study.}
  \label{fig:Methodology}
\end{figure}
\FloatBarrier

\section{Database}
As said in introduction, deep learning algorithms will be applied to face recognition in video surveillance system. A database of surveillance videos is required to generate a training set and a testing set for our model.
The database which will be used for the learning process is a set of 14 videos recorded in the MBK Shopping Center of Bangkok. The duration of the videos is variable, from a minute to around three minutes and thirty seconds. Three of the researchers of our laboratory appear on the videos, walking in the mall like any other person.

\section{Raw Database of Faces}

A C++ algorithm using OpenCV (Bradski, G. 2000) will process like so:

\begin{algorithm}[H]
 \For{each video in the database}{
 \For{each frame of the current video}{
 	Detect all the faces of the current frame N in the current video\;
  	Save P-th detected in \enquote{Database/video/FrameNFaceP.jpg}\;
  }
  }
 \caption{Face detection Algorithm}
\end{algorithm}

The algorithm used for face detection uses a machine learning process called Haar feature-based cascade classifiers, described in (Viola, Jones, 2001).

Once the process is over, a \enquote{Database} directory is created one directory for each video. In each directory, all the faces are saved as .jpg files.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/face1.jpg}
  \includegraphics[scale=0.7]{figures/face2.jpg}
  \caption[An example of two faces extracted from the surveillance system]{An example of two faces extracted from the surveillance system}
  \label{fig:face}
\end{figure}

\section{Creation of database files}

The framework which will be presented in the next section requires basically two files to work: a train.txt file and a test.txt file. Their role is trivially linked to their name in a supervised learning process. Each of those files share the same structure:

\blockquote{/adress/of/the/training/image1.jpg label\newline
/adress/of/the/training/image2.jpg label2\newline
...\newline
/adress/of/the/training/imageN.jpg labelN}

The label being 1 for the first of our researchers appearing in the surveillance system, 2 for the second one, 3 for the third one, and 0 for any other person.

The labelisation has to be done manually. The chosen method consists in modifying the name of the files where a researcher appears in this way:

\blockquote{filename.jpg becomes Kfilename.jpg}

K being the label of the researcher.

It is a feasible task to create a serie of python scripts which will run one after the other to create the required train.txt and test.txt files. These python scripts will be indirectly launched through bash scripts. A README file will be provided to explain which commands to type and which options to select to generate the required files from the database.\\

The purpose of the designed architecture is to make those scripts reusable for any new database, and generalizable for an arbitrary number of labels. If a user provides an other database of videos, and follows the process described in the README file, the required train.txt and test.txt files will be generated, and the models presented in the next section will can be used for learning or testing directly on his own data.

\section{Model}

\subsection{Framework}
The chosen deep learning framework for this study is Caffe (Jia et al., 2014). It is possible that Torch (Collobert, Kavukcuoglu, Farabet, 2011) will be used also, to some extent.\\

\subsection{Strategy}
Different strategies have been considered for this modelisation. As explained in the previous chapter, there are two usual schemes for face recognition.\newline
-The first one is the \enquote{same/not same} scheme. The idea is to readjust the Siamese Network described by (Lecun et al., 2005) to our particular dataset.\newline
-The second scheme is direct face identification. For this purpose, the idea is to modify the last layer of a state-of-the-art range deep neural network architecture for face identification. The output of this last modified layer should be binary. Either the input image represents one of our researchers -in practice, a criminal-, or either it is not. The previous layers should already be trained, and the training should be done on the last layer only.

\subsection{The learning process with Caffe}

The Caffe framework requires several files to learn the model.\\
-First, a train.txt and a test.txt files which give the path to all the images with their corresponding label.\newline
-Second, a train\_test.prototxt file which describes the architecture of the network. This file is written with protobuf. According to the README file available on the project's GitHub, \blockquote{Protocol Buffers (a.k.a., protobuf) are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data.}. The figure \ref{fig:logreg} shows how a logistic regression classifier is easily defined in a train\_test.prototxt file with Caffe.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/logreg.jpg}
  \includegraphics[scale=0.4]{figures/logregfile.png}
  \caption[Logistic regression classifier definition with Caffe. Extracted from the official website of the framework.]{Logistic regression classifier definition with Caffe. Extracted from the official website of the framework.}
  \label{fig:logreg}
\end{figure}

\FloatBarrier

-Third, a solver.prototxt file which contains informations on the batch size or on the variables related to the used loss function.

The learning process produces two files. A .caffemodel and a .solverstate. Those files are used to store the value of the parameters of the designed model after a number of steps of learning chosen in the .solverstate file.

\section{Testing}

As we just said, the output of a face identification model should be binary. A python script to test the accuracy of the model can be written with no difficulty. On the contrary, the input of a Siamese Network is two images and the output is an energy. This energy is high for two images representing two different persons and low else. A threshold on this energy has to be determined to make classification possible with the network. Thus, before any test, a script has to be written, determining a good threshold. This script should be written using pycaffe, the caffe model for python. Then, and only then can the tests be done.